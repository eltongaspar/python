{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8-4 Consolidar \n",
    "#Reconhecimento de Textos - OCR\n",
    "#Tensorflow, Learnig machine, Deep learnig, Mnisp, Kaglle\n",
    "\n",
    "#Importando as bibliotecas\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import zipfile\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.contours import sort_contours\n",
    "import imutils\n",
    "#from google.colab.patches import cv2_imshow\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando as bases de dados\n",
    "#Conjunto MNIST 0-9\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "\n",
    "train_data.shape, test_data.shape\n",
    "train_labels.shape, test_labels.shape\n",
    "\n",
    "digitos_data = np.vstack([train_data, test_data])\n",
    "digitos_labels = np.hstack([train_labels, test_labels])\n",
    "\n",
    "np.random.randint(0, digitos_data.shape[0])\n",
    "\n",
    "indice = np.random.randint(0, digitos_data.shape[0])\n",
    "plt.imshow(digitos_data[indice], cmap='gray')\n",
    "plt.title('Classe: ' + str(digitos_labels[indice]));\n",
    "\n",
    "sns.countplot(digitos_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conjunto Kaggle A-Z\n",
    "\n",
    "#!wget https://iaexpert.academy/arquivos/alfabeto_A-Z.zip\n",
    "#!wget https://drive.google.com/file/d/1BWkPbX5e76-x4yLxAorfgoSicq5ectx0/view?usp=sharing\n",
    "\n",
    "#zip_object = zipfile.ZipFile(file='/content/drive/MyDrive/alfabeto_A-Z.zip', mode = 'r')\n",
    "#zip_object.extractall('./')\n",
    "#zip_object.close()\n",
    "\n",
    "dataset_az = pd.read_csv(\"D:/Dados/alfabeto_A-Z/A_Z Handwritten Data.csv\").astype('float32')\n",
    "\n",
    "alfabeto_data = dataset_az.drop('0', axis = 1)\n",
    "alfabeto_labels = dataset_az['0']\n",
    "\n",
    "alfabeto_labels\n",
    "\n",
    "alfabeto_data = np.reshape(alfabeto_data.values, (alfabeto_data.shape[0], 28, 28))\n",
    "\n",
    "indice = np.random.randint(0, alfabeto_data.shape[0])\n",
    "plt.imshow(alfabeto_data[indice], cmap = 'gray')\n",
    "plt.title('Classe ' + str(alfabeto_labels[indice]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Junção das bases de dados\n",
    "\n",
    "digitos_labels, np.unique(digitos_labels)\n",
    "\n",
    "alfabeto_labels, np.unique(alfabeto_labels)\n",
    "\n",
    "alfabeto_labels += 10\n",
    "\n",
    "data = np.vstack([alfabeto_data, digitos_data])\n",
    "labels = np.hstack([alfabeto_labels, digitos_labels])\n",
    "\n",
    "data = np.array(data, dtype='float32')\n",
    "\n",
    "data = np.expand_dims(data, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pré-processamento dos dados\n",
    "\n",
    "data[0].min(), data[0].max()\n",
    "data /= 255.0\n",
    "np.unique(labels)\n",
    "\n",
    "le = LabelBinarizer()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "classes_total = labels.sum(axis=0)\n",
    "\n",
    "plt.imshow(data[30000].reshape(28,28), cmap='gray')\n",
    "plt.title(str(labels[30000]));\n",
    "\n",
    "classes_peso = {}\n",
    "for i in range(0, len(classes_total)):\n",
    "  #print(i)\n",
    "  classes_peso[i] = classes_total.max() / classes_total[i]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state = 1)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "augmentation = ImageDataGenerator(rotation_range=10, zoom_range=0.05, width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1, horizontal_flip = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação da estrutura da rede neural\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "rede_neural = Sequential()\n",
    "\n",
    "rede_neural.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "rede_neural.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "rede_neural.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "rede_neural.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "rede_neural.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='valid'))\n",
    "rede_neural.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "rede_neural.add(Flatten())\n",
    "\n",
    "rede_neural.add(Dense(64, activation='relu'))\n",
    "rede_neural.add(Dense(128, activation='relu'))\n",
    "\n",
    "rede_neural.add(Dense(36, activation='softmax'))\n",
    "\n",
    "rede_neural.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "rede_neural.summary()\n",
    "\n",
    "nomes_labels = '0123456789'\n",
    "nomes_labels += 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "nomes_labels = [l for l in nomes_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento da rede neural\n",
    "\n",
    "arquivo_modelo = 'manuscrito.keras'\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "checkpointer = ModelCheckpoint(arquivo_modelo, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "len(X_train) // batch_size\n",
    "\n",
    "history = rede_neural.fit(augmentation.flow(X_train, y_train, batch_size=batch_size),\n",
    "                                            validation_data = (X_test, y_test),\n",
    "                                            steps_per_epoch = len(X_train) // batch_size,\n",
    "                                            epochs = epochs,\n",
    "                                            class_weight = classes_peso,\n",
    "                                            verbose=1, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avaliação da rede neural\n",
    "previsoes = rede_neural.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "len(previsoes[0])\n",
    "\n",
    "np.argmax(previsoes[0])\n",
    "\n",
    "rede_neural.evaluate(X_test, y_test)\n",
    "\n",
    "history.history.keys()\n",
    "\n",
    "plt.plot(history.history['val_loss']);\n",
    "\n",
    "plt.plot(history.history['val_accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conectando com o Drive e acessando os arquivos\n",
    "#Carregando a rede neural\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "# Realize o dowload da pasta Material_complementar_reconhecimento_texto.zip do Google Sala de Aula e transira-a para o seu Google Drive\n",
    "# Localize o caminho da pasta no menu Arquivos, no menu lateral esquerdo\n",
    "#path = \"/content/drive/MyDrive/Material_complementar_reconhecimento_texto.zip\"\n",
    "#zip_object = zipfile.ZipFile(file=path, mode=\"r\")\n",
    "#zip_object.extractall(\"./\")\n",
    "#import tensorflow as tf\n",
    "\n",
    "rede_neural = load_model(\"D:/Dados/Material_complementar_reconhecimento_texto/modelos/rede_neural.h5\")\n",
    "#rede_neural = tf.keras.models.load_model(\"D:/Dados/Material_complementar_reconhecimento_texto/modelos/rede_neural\")\n",
    "rede_neural.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando a imagem de teste\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('D:/Dados/Material_complementar_reconhecimento_texto/imagens/manuscrito.jpg')\n",
    "#cv2_imshow(img)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "plt.show()\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#cv2_imshow(gray)\n",
    "plt.imshow(gray)\n",
    "plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pré-processamento da imagem\n",
    "desfoque = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "#cv2_imshow(desfoque)\n",
    "plt.imshow(desfoque)\n",
    "plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_media = cv2.adaptiveThreshold(desfoque, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 9)\n",
    "#cv2_imshow(adapt_media)\n",
    "plt.imshow(adapt_media)\n",
    "plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = 255 - adapt_media\n",
    "#cv2_imshow(inv)\n",
    "plt.imshow(adapt_media)\n",
    "plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilatado = cv2.dilate(inv, np.ones((3,3)))\n",
    "#cv2_imshow(dilatado)\n",
    "plt.imshow(dilatado)\n",
    "plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bordas = cv2.Canny(desfoque, 40, 150)\n",
    "#cv2_imshow(bordas)\n",
    "plt.imshow(dilatado)\n",
    "plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilatado = cv2.dilate(bordas, np.ones((3,3)))\n",
    "#cv2_imshow(dilatado)\n",
    "plt.imshow(dilatado)\n",
    "plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecção de contornos\n",
    "\n",
    "def encontrar_contornos(img):\n",
    "  conts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  conts = imutils.grab_contours(conts)\n",
    "  conts = sort_contours(conts, method='left-to-right')[0]\n",
    "  return conts\n",
    "\n",
    "conts = encontrar_contornos(dilatado.copy())\n",
    "\n",
    "l_min, l_max = 4, 160\n",
    "a_min, a_max = 14, 140\n",
    "\n",
    "caracteres = []\n",
    "img_cp = img.copy()\n",
    "for c in conts:\n",
    "  #print(c)\n",
    "  (x, y, w, h) = cv2.boundingRect(c)\n",
    "  #print(x, y, w, h)\n",
    "  if (w >= l_min and w <= l_max) and (h >= a_min and h <= a_max):\n",
    "    roi = gray[y:y+ h, x:x + w]\n",
    "    #cv2_imshow(roi)\n",
    "    thresh = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    #cv2_imshow(thresh)\n",
    "    plt.imshow(thresh)\n",
    "    plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "    plt.show()\n",
    "    cv2.rectangle(img_cp, (x, y), (x + w, y + h), (255, 100, 0), 2)\n",
    "#cv2_imshow(img_cp)\n",
    "plt.imshow(img_cp)\n",
    "plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processando os caracteres detectados\n",
    "#Extração ROI\n",
    "def extra_roi(img):\n",
    "  roi = img[y:y + h, x:x + w]\n",
    "  return roi\n",
    "\n",
    "#Limiarização\n",
    "def limiarizacao(img):\n",
    "  thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "  return thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimensionamento\n",
    "\n",
    "def redimensiona_img(img, l, a):\n",
    "  if l > a:\n",
    "    redimensionada = imutils.resize(img, width=28)\n",
    "  else:\n",
    "    redimensionada = imutils.resize(img, height=28)\n",
    "\n",
    "  (a, l) = redimensionada.shape\n",
    "  dX = int(max(0, 28 - l) / 2.0)\n",
    "  dY = int(max(0, 28 - a) / 2.0)\n",
    "\n",
    "  preenchida = cv2.copyMakeBorder(redimensionada, top=dY, bottom=dY, right=dX, left=dX, borderType=cv2.BORDER_CONSTANT, value=(0,0,0))\n",
    "  preenchida = cv2.resize(preenchida, (28, 28))\n",
    "  return preenchida\n",
    "\n",
    "  (x, y, w, h) = cv2.boundingRect(conts[6])\n",
    "print(x, y, w, h)\n",
    "img_teste = limiarizacao(gray[y:y+h, x:x+w])\n",
    "#cv2_imshow(img_teste)\n",
    "plt.imshow(img_teste)\n",
    "plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "plt.show()\n",
    "(a, l) = img_teste.shape\n",
    "print(a, l)\n",
    "img_teste2 = redimensiona_img(img_teste, l, a)\n",
    "#Cv2_imshow(img_teste2)\n",
    "plt.imshow(img_teste2)\n",
    "plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "plt.show()\n",
    "img_teste2.shape\n",
    "\n",
    "#cv2_imshow(cv2.resize(img_teste, (28,28)))\n",
    "plt.imshow(cv2.resize(img_teste, (28,28)))\n",
    "plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalização\n",
    "\n",
    "def normalizacao(img):\n",
    "  img = img.astype('float32') / 255.0\n",
    "  img = np.expand_dims(img, axis=-1)\n",
    "  return img\n",
    "\n",
    "  img_teste2.shape, normalizacao(img_teste2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processamento das detecções\n",
    "def processa_caixa(gray, x, y, w, h):\n",
    "  roi = extra_roi(gray)\n",
    "  limiar = limiarizacao(roi)\n",
    "  (a, l) = limiar.shape\n",
    "  redimensionada = redimensiona_img(limiar, l, a)\n",
    "  #cv2_imshow(redimensionada)\n",
    "  plt.imshow(redimensionada)\n",
    "  plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "  plt.show()\n",
    "  normalizada = normalizacao(redimensionada)\n",
    "  caracteres.append((normalizada, (x, y, w, h)))\n",
    "\n",
    "\n",
    "for c in conts:\n",
    "  #print(c)\n",
    "  (x, y, w, h) = cv2.boundingRect(c)\n",
    "  if (w >= l_min and w <= l_max) and (h >= a_min and h <= a_max):\n",
    "    processa_caixa(gray, x, y, w, h)\n",
    "\n",
    "caixas = [caixa[1] for caixa in caracteres]\n",
    "caracteres = np.array([c[0] for c in caracteres], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconhecimento dos caracteres\n",
    "numeros = \"0123456789\"\n",
    "letras = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "lista_caracteres = numeros + letras\n",
    "lista_caracteres = [l for l in lista_caracteres]\n",
    "\n",
    "caracteres[0].shape\n",
    "\n",
    "caracteres.shape\n",
    "\n",
    "previsoes = rede_neural.predict(caracteres)\n",
    "\n",
    "previsoes.shape\n",
    "\n",
    "img_cp = img.copy()\n",
    "for (previsoes, (x, y, w, h)) in zip(previsoes, caixas):\n",
    "  i = np.argmax(previsoes)\n",
    "  #print(i)\n",
    "  probabilidade = previsoes[i]\n",
    "  #print(probabilidade)\n",
    "  caractere = lista_caracteres[i]\n",
    "  #print(caractere)\n",
    "\n",
    "  cv2.rectangle(img_cp, (x, y), (x + w, y + h), (255,100,0), 2)\n",
    "  cv2.putText(img_cp, caractere, (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.1, (0,0,255), 2)\n",
    "  print(caractere, ' -> ', probabilidade * 100)\n",
    "\n",
    "  #v2_imshow(img_cp)\n",
    "  plt.imshow(img_cp)\n",
    "  plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "  plt.show()\n",
    "\n",
    "def extrai_roi(img, margem=2):\n",
    "  roi = img[y - margem:y + h + margem, x - margem:x + w + margem]\n",
    "  return roi\n",
    "\n",
    "\n",
    "conts = encontrar_contornos(dilatado.copy())\n",
    "caracteres = []\n",
    "for c in conts:\n",
    "  (x, y, w, h) = cv2.boundingRect(c)\n",
    "  if (w >= l_min and w <= l_max) and (h >= a_min and h <= a_max):\n",
    "    processa_caixa(gray, x, y, w, h)\n",
    "\n",
    "\n",
    "caixas = [b[1] for b in caracteres]\n",
    "caracteres = np.array([c[0] for c in caracteres], dtype=\"float32\")\n",
    "previsoes = rede_neural.predict(caracteres)\n",
    "\n",
    "img_cp = img.copy()\n",
    "for (previsoes, (x, y, w, h)) in zip(previsoes, caixas):\n",
    "  i = np.argmax(previsoes)\n",
    "  probabilidade = previsoes[i]\n",
    "  caractere = lista_caracteres[i]\n",
    "\n",
    "  cv2.rectangle(img_cp, (x, y), (x + w, y + h), (255,100,0), 2)\n",
    "  cv2.putText(img_cp, caractere, (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.1, (0,0,255), 2)\n",
    "  print(caractere, ' -> ', probabilidade * 100)\n",
    "\n",
    "  #cv2_imshow(img_cp)\n",
    "  plt.imshow(img_cp)\n",
    "  plt.axis('off')  # Desativar eixos para uma visualização mais limpa\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
