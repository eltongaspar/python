#Reconhecimento de Raio-x Pneumonia

#Introdução + Configuração
#Este tutorial explicará como construir um modelo de classificação de imagens de raios X para prever se uma radiografia mostra a presença de pneumonia.

#Importando as biblioteca s
import re
import os
import random
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt

#Calcular Tempo 
import datetime
data_hora_atual_ini = datetime.datetime.now()
print(" \n Inicio",data_hora_atual_ini)


#Esse trecho de código é usado para configurar a estratégia de treinamento distribuído no TensorFlow, especificamente para treinamento em unidades de processamento tensorial (TPUs) ou em múltiplas GPUs.
#Aqui está uma explicação passo a passo do que o código faz:
#Tenta conectar-se a um ClusterResolver para detectar e conectar-se a uma TPU. Se uma TPU for detectada, a estratégia de treinamento é configurada para utilizar a TPU.
#Se não houver uma TPU disponível (ou ocorrer algum erro ao tentar conectar-se), o código continua sem uma estratégia específica, o que significa que o treinamento será realizado em uma única GPU ou CPU, dependendo da configuração padrão.
#O número de réplicas é então impresso, que indica o número total de dispositivos (TPUs, GPUs ou CPUs) disponíveis para treinamento.
#Se você estiver executando este código em um ambiente que suporta TPUs e tiver uma TPU disponível, ele irá configurar automaticamente a estratégia de treinamento para utilizar a TPU. Caso contrário, ele continuará sem a estratégia específica e o treinamento será feito localmente.

try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()
    print("Device:", tpu.master())
    strategy = tf.distribute.TPUStrategy(tpu)
except:
    strategy = tf.distribute.get_strategy()
print("Number of replicas:", strategy.num_replicas_in_sync)

#Precisamos de um link do Google Cloud para nossos dados para carregá-los usando uma TPU. Abaixo, definimos os principais parâmetros de configuração que usaremos neste exemplo. Para executar na TPU, este exemplo deve estar no Colab com o tempo de execução da TPU selecionado.
AUTOTUNE = tf.data.AUTOTUNE
BATCH_SIZE = 25 * strategy.num_replicas_in_sync
IMAGE_SIZE = [180, 180]
CLASS_NAMES = ["NORMAL", "PNEUMONIA"]


#Carregue os dados
#Os dados de radiografia de tórax que usamos do Cell dividem os dados em arquivos de treinamento e teste. Vamos primeiro carregar os TFRecords de treinamento.
train_images = tf.data.TFRecordDataset(
    "gs://download.tensorflow.org/data/ChestXRay2017/train/images.tfrec"
)
train_paths = tf.data.TFRecordDataset(
    "gs://download.tensorflow.org/data/ChestXRay2017/train/paths.tfrec"
)

ds = tf.data.Dataset.zip((train_images, train_paths))

#Vamos contar quantas radiografias de tórax saudáveis/normais temos e quantas radiografias de tórax de pneumonia temos:
COUNT_NORMAL = len(
    [
        filename
        for filename in train_paths
        if "NORMAL" in filename.numpy().decode("utf-8")
    ]
)
print("Normal images count in training set: " + str(COUNT_NORMAL))

COUNT_PNEUMONIA = len(
    [
        filename
        for filename in train_paths
        if "PNEUMONIA" in filename.numpy().decode("utf-8")
    ]
)
print("Pneumonia images count in training set: " + str(COUNT_PNEUMONIA))


#Observe que há muito mais imagens classificadas como pneumonia do que o normal. Isso mostra que temos um desequilíbrio em nossos dados. Corrigiremos esse desequilíbrio mais tarde em nosso caderno.
#Queremos mapear cada nome de arquivo para o par correspondente (imagem, rótulo). Os métodos a seguir nos ajudarão a fazer isso.
#Como temos apenas dois rótulos, codificaremos o rótulo para que 1ou Trueindique pneumonia e 0ou Falseindique normal.
def get_label(file_path):
    # convert the path to a list of path components
    parts = tf.strings.split(file_path, "/")
    # The second to last is the class-directory
    if parts[-2] == "PNEUMONIA":
        return 1
    else:
        return 0


def decode_img(img):
    # convert the compressed string to a 3D uint8 tensor
    img = tf.image.decode_jpeg(img, channels=3)
    # resize the image to the desired size.
    return tf.image.resize(img, IMAGE_SIZE)


def process_path(image, path):
    label = get_label(path)
    # load the raw data from the file as a string
    img = decode_img(image)
    return img, label


ds = ds.map(process_path, num_parallel_calls=AUTOTUNE)

#Vamos dividir os dados em conjuntos de dados de treinamento e validação.
ds = ds.shuffle(10000)
train_ds = ds.take(4200)
val_ds = ds.skip(4200)

#Vamos visualizar a forma de um par (imagem, rótulo).
for image, label in train_ds.take(1):
    print("Image shape: ", image.numpy().shape)
    print("Label: ", label.numpy())
    
#Carregue e formate os dados de teste também.
test_images = tf.data.TFRecordDataset(
    "gs://download.tensorflow.org/data/ChestXRay2017/test/images.tfrec"
)
test_paths = tf.data.TFRecordDataset(
    "gs://download.tensorflow.org/data/ChestXRay2017/test/paths.tfrec"
)
test_ds = tf.data.Dataset.zip((test_images, test_paths))

test_ds = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)
test_ds = test_ds.batch(BATCH_SIZE)

#Visualize o conjunto de dados
#Primeiro, vamos usar a pré-busca em buffer para que possamos gerar dados do disco sem que a E/S se torne um bloqueio.
#Observe que grandes conjuntos de dados de imagens não devem ser armazenados em cache na memória. Fazemos isso aqui porque o conjunto de dados não é muito grande e queremos treinar em TPU.
def prepare_for_training(ds, cache=True):
    # This is a small dataset, only load it once, and keep it in memory.
    # use `.cache(filename)` to cache preprocessing work for datasets that don't
    # fit in memory.
    if cache:
        if isinstance(cache, str):
            ds = ds.cache(cache)
        else:
            ds = ds.cache()

    ds = ds.batch(BATCH_SIZE)

    # `prefetch` lets the dataset fetch batches in the background while the model
    # is training.
    ds = ds.prefetch(buffer_size=AUTOTUNE)

    return ds

#Chame a próxima iteração em lote dos dados de treinamento.
train_ds = prepare_for_training(train_ds)
val_ds = prepare_for_training(val_ds)

image_batch, label_batch = next(iter(train_ds))

#Defina o método para mostrar as imagens do lote.
def show_batch(image_batch, label_batch):
    plt.figure(figsize=(10, 10))
    for n in range(25):
        ax = plt.subplot(5, 5, n + 1)
        plt.imshow(image_batch[n] / 255)
        if label_batch[n]:
            plt.title("PNEUMONIA")
        else:
            plt.title("NORMAL")
        plt.axis("off")
        
#Como o método aceita arrays NumPy como parâmetros, chame a função numpy nos lotes para retornar o tensor no formato de array NumPy.
show_batch(image_batch.numpy(), label_batch.numpy())

#Construa a CNN
#Para tornar nosso modelo mais modular e de fácil compreensão, vamos definir alguns blocos. À medida que construímos uma rede neural de convolução, criaremos um bloco de convolução e um bloco de camada densa.
#A arquitetura desta CNN foi inspirada neste artigo .
import os 
os.environ['KERAS_BACKEND'] = 'tensorflow'

import keras
from keras import layers

def conv_block(filters, inputs):
    x = layers.SeparableConv2D(filters, 3, activation="relu", padding="same")(inputs)
    x = layers.SeparableConv2D(filters, 3, activation="relu", padding="same")(x)
    x = layers.BatchNormalization()(x)
    outputs = layers.MaxPool2D()(x)

    return outputs


def dense_block(units, dropout_rate, inputs):
    x = layers.Dense(units, activation="relu")(inputs)
    x = layers.BatchNormalization()(x)
    outputs = layers.Dropout(dropout_rate)(x)

    return outputs

#O método a seguir definirá a função para construir nosso modelo para nós.
#As imagens originalmente possuem valores que variam de [0, 255]. As CNNs funcionam melhor com números menores, então reduziremos isso para nossa contribuição.
#As camadas Dropout são importantes, pois reduzem a probabilidade de overfitting do modelo. Queremos finalizar o modelo com uma Dense camada com um nó, pois esta será a saída binária que determinará se uma radiografia mostra presença de pneumonia.
def build_model():
    inputs = keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))
    x = layers.Rescaling(1.0 / 255)(inputs)
    x = layers.Conv2D(16, 3, activation="relu", padding="same")(x)
    x = layers.Conv2D(16, 3, activation="relu", padding="same")(x)
    x = layers.MaxPool2D()(x)

    x = conv_block(32, x)
    x = conv_block(64, x)

    x = conv_block(128, x)
    x = layers.Dropout(0.2)(x)

    x = conv_block(256, x)
    x = layers.Dropout(0.2)(x)

    x = layers.Flatten()(x)
    x = dense_block(512, 0.7, x)
    x = dense_block(128, 0.5, x)
    x = dense_block(64, 0.3, x)

    outputs = layers.Dense(1, activation="sigmoid")(x)

    model = keras.Model(inputs=inputs, outputs=outputs)
    return model

#Corrigir para desequilíbrio de dados
#Vimos anteriormente neste exemplo que os dados estavam desequilibrados, com mais imagens classificadas como pneumonia do que o normal. Corrigiremos isso usando ponderação de classe:
#O peso da classe 0(Normal) é muito superior ao peso da classe 1 (Pneumonia). Como há menos imagens normais, cada imagem normal terá mais peso para equilibrar os dados, pois a CNN funciona melhor quando os dados de treinamento são balanceados.
initial_bias = np.log([COUNT_PNEUMONIA / COUNT_NORMAL])
print("Initial bias: {:.5f}".format(initial_bias[0]))

TRAIN_IMG_COUNT = COUNT_NORMAL + COUNT_PNEUMONIA
weight_for_0 = (1 / COUNT_NORMAL) * (TRAIN_IMG_COUNT) / 2.0
weight_for_1 = (1 / COUNT_PNEUMONIA) * (TRAIN_IMG_COUNT) / 2.0

class_weight = {0: weight_for_0, 1: weight_for_1}

print("Weight for class 0: {:.2f}".format(weight_for_0))
print("Weight for class 1: {:.2f}".format(weight_for_1))

#Treine o modelo
#Definindo retornos de chamada
#O retorno de chamada do ponto de verificação salva os melhores pesos do modelo, portanto, da próxima vez que quisermos usar o modelo, não precisaremos perder tempo treinando-o. O retorno de chamada de parada antecipada interrompe o processo de treinamento quando o modelo começa a ficar estagnado ou, pior ainda, quando o modelo começa a se ajustar demais.
early_stopping_cb = keras.callbacks.EarlyStopping(
    patience=10, restore_best_weights=True
)

#Também queremos ajustar nossa taxa de aprendizado. Uma taxa de aprendizado muito alta fará com que o modelo diverja. Uma taxa de aprendizado muito pequena fará com que o modelo seja muito lento. Implementamos o método de agendamento de taxa de aprendizagem exponencial abaixo.
checkpoint_cb = keras.callbacks.ModelCheckpoint("xray_model.keras", save_best_only=True)
initial_learning_rate = 0.015
lr_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True
)

#Ajuste o modelo
#Para nossas métricas, queremos incluir precisão e recall, pois elas fornecerão ao usuário uma imagem mais informada de quão bom é nosso modelo. A precisão nos diz qual fração dos rótulos está correta. Dado que os nossos dados não são equilibrados, a precisão pode dar uma sensação distorcida de um bom modelo (ou seja, um modelo que prevê sempre PNEUMONIA será 74% preciso, mas não é um bom modelo).
#A precisão é o número de verdadeiros positivos (TP) sobre a soma de TP e falsos positivos (FP). Mostra qual fração de positivos rotulados está realmente correta.
#Recall é o número de TP sobre a soma de TP e falsos negativos (FN). Mostra qual fração dos positivos reais está correta.
#Como existem apenas dois rótulos possíveis para a imagem, usaremos a perda binária de entropia cruzada. Ao ajustar o modelo, lembre-se de especificar os pesos das classes, que definimos anteriormente. Como estamos usando uma TPU, o treinamento será rápido – menos de 2 minutos.
with strategy.scope():
    model = build_model()

    METRICS = [
        keras.metrics.BinaryAccuracy(),
        keras.metrics.Precision(name="precision"),
        keras.metrics.Recall(name="recall"),
    ]
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),
        loss="binary_crossentropy",
        metrics=METRICS,
    )

history = model.fit(
    train_ds,
    epochs=100,
    validation_data=val_ds,
    class_weight=class_weight,
    callbacks=[checkpoint_cb, early_stopping_cb],
)

#Visualizando o desempenho do modelo
#Vamos representar graficamente a precisão e a perda do modelo para o conjunto de treinamento e validação. Observe que nenhuma semente aleatória é especificada para este notebook. Para o seu notebook, pode haver uma pequena variação.
ig, ax = plt.subplots(1, 4, figsize=(20, 3))
ax = ax.ravel()

for i, met in enumerate(["precision", "recall", "binary_accuracy", "loss"]):
    ax[i].plot(history.history[met])
    ax[i].plot(history.history["val_" + met])
    ax[i].set_title("Model {}".format(met))
    ax[i].set_xlabel("epochs")
    ax[i].set_ylabel(met)
    ax[i].legend(["train", "val"])
#Vemos que a precisão do nosso modelo está em torno de 95%.

#Prever e avaliar resultados
#Vamos avaliar o modelo em nossos dados de teste!
model.evaluate(test_ds, return_dict=True)

#Vemos que nossa precisão em nossos dados de teste é inferior à precisão de nosso conjunto de validação. Isso pode indicar sobreajuste.
#Nossa recordação é maior que nossa precisão, indicando que quase todas as imagens de pneumonia são identificadas corretamente, mas algumas imagens normais são falsamente identificadas. Devemos ter como objetivo aumentar a nossa precisão.
    

#Calcular Tempo 
data_hora_atual_fim = datetime.datetime.now()
print("\n Fim",data_hora_atual_fim)
tempo = data_hora_atual_fim - data_hora_atual_ini
print('\n Tempo',tempo)
