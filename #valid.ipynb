{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Carregar os dados da planilha Excel\n",
    "df = pd.read_excel(\"D:/Dados/Fintech/Modelo FinTech.xlsx\")\n",
    "\n",
    "# Separar os dados em features (X) e target (y)\n",
    "X = df.drop('Valor', axis=1)\n",
    "y = df['Categoria']\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Definir a arquitetura da rede neural\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Avaliar o modelo\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n",
    "\n",
    "# Fazer previsões\n",
    "predictions = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "# Carregar dados do Excel\n",
    "dados = pd.read_excel(\"D:/Dados/Fintech/Modelo FinTech.xlsx\")\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "# ... (limpar, normalizar, etc.)\n",
    "\n",
    "# Dividir em conjuntos de treinamento e teste\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(dados_pre_processados, labels, test_size=0.2)\n",
    "\n",
    "# Criar o modelo de rede neural\n",
    "modelo = Sequential()\n",
    "modelo.add(Dense(64, activation='relu', input_dim=X_treino.shape[1]))\n",
    "modelo.add(Dense(32, activation='relu'))\n",
    "modelo.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilar o modelo\n",
    "modelo.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "modelo.fit(X_treino, y_treino, epochs=10000, batch_size=32)\n",
    "\n",
    "# Avaliar o modelo\n",
    "resultado = modelo.evaluate(X_teste, y_teste)\n",
    "print('Precisão:', resultado[1])\n",
    "\n",
    "# Fazer previsões em novos dados\n",
    "novo_cliente = # ... (dados do novo cliente)\n",
    "previsao = modelo.predict(novo_cliente.reshape(1, -1))\n",
    "if previsao > 0.5:\n",
    "    print('Previsão: Compra provável')\n",
    "else:\n",
    "    print('Previsão: Compra improvável')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercicio 64 \n",
    "#Classificador de Imagens caes e gatos \n",
    "\n",
    "#Importando as bibliotecas \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "#from google.colab.patches import cv2_imshow\n",
    "tf.__version__\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "#Calcular Tempo \n",
    "import datetime\n",
    "data_hora_atual_ini = datetime.datetime.now()\n",
    "print(\" \\n Inicio\",data_hora_atual_ini)\n",
    "\n",
    "def escolher_arquivo_aleatorio(caminho_da_pasta):\n",
    "    # Lista todos os arquivos na pasta\n",
    "    arquivos = os.listdir(caminho_da_pasta)\n",
    "    \n",
    "    # Filtra apenas os arquivos (remove pastas)\n",
    "    arquivos = [arquivo for arquivo in arquivos if os.path.isfile(os.path.join(caminho_da_pasta, arquivo))]\n",
    "    \n",
    "    # Escolhe um arquivo aleatoriamente\n",
    "    arquivo_aleatorio = random.choice(arquivos)\n",
    "    \n",
    "    # Retorna o caminho completo do arquivo escolhido\n",
    "    return os.path.join(caminho_da_pasta, arquivo_aleatorio)\n",
    "\n",
    "# Exemplo de uso\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "def escolher_arquivo_aleatorio(caminho_da_pasta):\n",
    "    # Lista todos os arquivos na pasta\n",
    "    arquivos = os.listdir(caminho_da_pasta)\n",
    "    \n",
    "    # Filtra apenas os arquivos (remove pastas)\n",
    "    arquivos = [arquivo for arquivo in arquivos if os.path.isfile(os.path.join(caminho_da_pasta, arquivo))]\n",
    "    \n",
    "    # Escolhe um arquivo aleatoriamente\n",
    "    arquivo_aleatorio = random.choice(arquivos)\n",
    "    \n",
    "    # Retorna o caminho completo do arquivo escolhido\n",
    "    return os.path.join(caminho_da_pasta, arquivo_aleatorio)\n",
    "\n",
    "\n",
    "# Funcao Gerar numero\n",
    "def num_aleat(num_min,num_max):\n",
    "    import random\n",
    "    num_ger = random.randrange(num_min,num_max)\n",
    "    return num_ger\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Conexão do Google Colava à pasta do Google Drive, local onde deverá ter salvo a pasta caes-e-gatos.zip\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "# Descompactar a pasta caes-e-gatos na pasta de Arquivos do Google Colab\n",
    "#path = '/content/drive/MyDrive/caes-e-gatos.zip'\n",
    "#zip_object = zipfile.ZipFile(file=path, mode='r')\n",
    "#zip_object.extractall('./')\n",
    "#zip_object.close()\n",
    "\n",
    "#Carregamento das imagens\n",
    "# Localizar o caminho da primeira imagem de gato na pasta treinamento\n",
    "cat_arq_ini = 'E:/Dados/caes-e-gatos/treinamento/gato/cat.0.jpg'\n",
    "tf.keras.preprocessing.image.load_img(cat_arq_ini)\n",
    "\n",
    "# Localizar o caminho da primeira imagem de cão na pasta treinamento\n",
    "dog_arq_ini = 'E:/Dados/caes-e-gatos/treinamento/cao/dog.0.jpg'\n",
    "tf.keras.preprocessing.image.load_img(dog_arq_ini)\n",
    "\n",
    "#Base de treinamento e teste\n",
    "# Localizar as 4000 imagens, nas duas classes para a base de treinamento\n",
    "dir_train = 'E:/Dados/caes-e-gatos/treinamento/'\n",
    "gerador_treinamento = ImageDataGenerator(rescale=1./255,\n",
    "                                        rotation_range=7,\n",
    "                                        horizontal_flip=True,\n",
    "                                        zoom_range=0.2)\n",
    "dataset_treinamento = gerador_treinamento.flow_from_directory(dir_train,\n",
    "                                                        target_size = (64, 64),\n",
    "                                                        batch_size = 32,\n",
    "                                                        class_mode = 'categorical',\n",
    "                                                        shuffle = True)\n",
    "\n",
    "\n",
    "\n",
    "# Estabelecendo índices para as classes no treinamento 0: cão e 1: gato\n",
    "dataset_treinamento.class_indices                                                        \n",
    "\n",
    "# Localizar o campinho para a paste de teste, contendo 1000 imagens com as duas classes\n",
    "dir_test = 'E:/Dados/caes-e-gatos/teste/'\n",
    "gerador_teste = ImageDataGenerator(rescale=1./255)\n",
    "dataset_teste = gerador_teste.flow_from_directory(dir_test,\n",
    "                                                     target_size = (64, 64),\n",
    "                                                     batch_size = 1,\n",
    "                                                     class_mode = 'categorical',\n",
    "                                                     shuffle = False)\n",
    "\n",
    "\n",
    "#Construção e treinamento da rede neural\n",
    "# Criando cada camada da rede neural, conforme o modelo sequencial da rede neural convolucional\n",
    "network = Sequential()\n",
    "network.add(Conv2D(32, (3,3), input_shape = (64,64,3), activation='relu'))\n",
    "network.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "network.add(Conv2D(32, (3,3), activation='relu'))\n",
    "network.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "network.add(Flatten())\n",
    "\n",
    "network.add(Dense(units = 3137, activation='relu'))\n",
    "network.add(Dense(units = 3137, activation='relu'))\n",
    "network.add(Dense(units = 2, activation='softmax'))\n",
    "\n",
    "# Visualizando o modelo com as classes criadas\n",
    "network.summary()\n",
    "\n",
    "# Estabelecendo as taxas de perda e acurácia para o modelo\n",
    "network.compile(optimizer='Adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Treinando o modelo com 10 épocas de treinamento\n",
    "# OBSERVAÇÃO: esta execução pode demorar conforme o desempenho de sua máquina\n",
    "historico = network.fit(dataset_treinamento, epochs=1000)\n",
    "\n",
    "# Avaliação da rede neural\n",
    "# Estabelecendo índices para as classes no teste 0: cão e 1: gato\n",
    "dataset_teste.class_indices\n",
    "\n",
    "# Trazendo ao modelo as predições do treinamento\n",
    "previsoes = network.predict(dataset_teste)\n",
    "\n",
    "# Verificando a máxima previsão para as classes\n",
    "previsoes = np.argmax(previsoes, axis = 1)\n",
    "\n",
    "# Verificando os dados do modelo treinado\n",
    "dataset_teste.classes\n",
    "\n",
    "# Demonstrando a acurácia do modelo treinado\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(dataset_teste.classes, previsoes)\n",
    "\n",
    "#OBSERVAÇÃO: o valor demonstrado acima é a precisão do treinamento do modelo. Valores quanto mais próximos de 1, mais precisa será a classificação. Para aumentar a precisão, pode-se retreinar o modelo ou ainda inserir mais imagens para o treinamento\n",
    "\n",
    "# Atribuindo as classes ao modelo treinado\n",
    "dataset_teste.class_indices\n",
    "\n",
    "# Estabelecendo a matriz de confusão para confronto do dados entre as classes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(dataset_teste.classes, previsoes)\n",
    "\n",
    "# Demonstrando a matriz de confusão\n",
    "sns.heatmap(cm, annot=True);\n",
    "\n",
    "# Classificando os dados obtidos\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(dataset_teste.classes, previsoes))\n",
    "\n",
    "# Salvar e carregar a rede neural\n",
    "# Gerando um arquivo .json com os dados do modelo\n",
    "model_json = network.to_json()\n",
    "with open('network.json','w') as json_file:\n",
    "  json_file.write(model_json)\n",
    "\n",
    "  # Criando o arquivo de pesos (pesos.hdf5) do treinamento\n",
    "dir_salv_pesos_keras = 'E:/Dados/caes-e-gatos/pesos.keras'\n",
    "from keras.models import save_model\n",
    "network_saved = save_model(network, dir_salv_pesos_keras)\n",
    "\n",
    "# Visualizando os dados salvos no arquivo .json\n",
    "dir_salv_json = 'E:/Dados/caes-e-gatos/network.json'\n",
    "with open('network.json', 'r') as json_file:\n",
    "  json_saved_model = json_file.read()\n",
    "json_saved_model\n",
    "\n",
    "# Atribuindo o treinamento ao modelo\n",
    "network_loaded = tf.keras.models.model_from_json(json_saved_model)\n",
    "network_loaded.load_weights(dir_salv_pesos_keras)\n",
    "network_loaded.compile(loss = 'categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "# Visualizando o modelo de rede neural\n",
    "network_loaded.summary()\n",
    "\n",
    "\n",
    "\n",
    "# Gera um numero aleatorio de 1 a 4 para os diretorios \n",
    "# Por funcao retorma o numero o numero aleatorio\n",
    "num_ger = num_aleat(1,4)\n",
    "\n",
    "if num_ger == 1:\n",
    "    caminho_da_pasta = 'E:/Dados/caes-e-gatos/teste/cao/'\n",
    "elif num_ger == 2:\n",
    "    caminho_da_pasta = 'E:/Dados/caes-e-gatos/teste/gato/'\n",
    "elif num_ger == 3:\n",
    "    caminho_da_pasta = 'E:/Dados/caes-e-gatos/treinamento/cao/'\n",
    "elif num_ger == 4:\n",
    "    caminho_da_pasta = 'E:/Dados/caes-e-gatos/treinamento/gato/'\n",
    "\n",
    "# Apos diretorio aleatorio, escolhe arquivo aleatorio para analise\n",
    "# Assim é possivel juntar mais de um diretório\n",
    "arquivo_aleatorio = escolher_arquivo_aleatorio(caminho_da_pasta)\n",
    "print(\"Arquivo escolhido aleatoriamente:\", arquivo_aleatorio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Classificação de uma única imagem\n",
    "# Na pasta teste, localize qualquer imagem para a classificação, conforme o modelo treinado\n",
    "# Abre o arquivo de imagem\n",
    "dir_arq_analise  = arquivo_aleatorio\n",
    "imagem = cv2.imread(arquivo_aleatorio)\n",
    "#imagem = Image.open(arquivo_aleatorio)\n",
    "   \n",
    "# Exibe a imagem\n",
    "plt.show()\n",
    "plt.imshow(imagem)\n",
    "#imagem.show()\n",
    "#imagem = cv2.imread('/content/caes-e-gatos/teste/cao/dog.3501.jpg')\n",
    "\n",
    "\n",
    "# Redimensionando a imagem em 64x64 pixels\n",
    "imagem = cv2.resize(imagem, (64, 64))\n",
    "#cv2_imshow(imagem)\n",
    "plt.show()\n",
    "\n",
    "# Convertendo em escala de cinza\n",
    "imagem = imagem / 255\n",
    "\n",
    "# Parâmetros da imagem redimensionada\n",
    "imagem = imagem.reshape(-1, 64, 64, 3)\n",
    "imagem.shape\n",
    "\n",
    "resultado = network_loaded(imagem)\n",
    "resultado\n",
    "\n",
    "# Demonstrando a classe que obteve o maior resultado\n",
    "resultado = np.argmax(resultado)\n",
    "resultado\n",
    "print(resultado)\n",
    "\n",
    "# Verificando as classes do modelo\n",
    "dataset_teste.class_indices\n",
    "print(dataset_teste)\n",
    "\n",
    "# Categorizando o resultado\n",
    "if resultado == 0:\n",
    "  print('Cão')\n",
    "else:\n",
    "  print('Gato')\n",
    "\n",
    "  #Calcular Tempo \n",
    "data_hora_atual_fim = datetime.datetime.now()\n",
    "print(\"\\n Fim\",data_hora_atual_fim)\n",
    "tempo = data_hora_atual_fim - data_hora_atual_ini\n",
    "print('\\n Tempo',tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifra_de_cesar_modificada(texto, deslocamento):\n",
    "    resultado = ''\n",
    "    deslocamento_atual = deslocamento\n",
    "    for char in texto:\n",
    "        if char.isalpha():\n",
    "            if char.islower():\n",
    "                novo_char = chr(((ord(char) - ord('a') + deslocamento_atual) % 26) + ord('a'))\n",
    "            else:\n",
    "                novo_char = chr(((ord(char) - ord('A') + deslocamento_atual) % 26) + ord('A'))\n",
    "            resultado += novo_char\n",
    "            deslocamento_atual += 1\n",
    "        else:\n",
    "            resultado += char\n",
    "    return resultado\n",
    "\n",
    "# Exemplo de uso:\n",
    "texto = \"A\"\n",
    "deslocamento = 3\n",
    "texto_cifrado = cifra_de_cesar_modificada(texto, deslocamento)\n",
    "print(\"Texto cifrado:\", texto_cifrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifra_cesar_modificada (texto,deslocamento):\n",
    "\tresultado = ''\n",
    "\tfor char in texto:\n",
    "\t\tif char.isalpha():\n",
    "\t\t\tshift = ord(char) + deslocamento\n",
    "\t\t\tif char.islower():\n",
    "\t\t\t\tresultado += chr((shift - 97) % 26 + 97)\n",
    "\t\t\telse:\n",
    "\t\t\t\tresultado += chr((shift -65) % 26 + 65)\n",
    "\t\t\tdeslocamento +=1\n",
    "\t\telse:\n",
    "\t\t\tresultado += char\n",
    "\treturn resultado\n",
    "\n",
    "texto = 'AaBbCc1234567'\n",
    "deslocamento = 1\n",
    "resultado = cifra_cesar_modificada(texto,deslocamento)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_numeros (num1,num2):\n",
    "\t\tif num1 > num2 and (num1 % num2) == 0:\n",
    "\t\t\treturn \"O primeiro numero é > e / pelo segundo\"\n",
    "\t\telif num1 > num2:\n",
    "\t\t\treturn \"O primeio numero é > que o segundo mas não é /\"\n",
    "\t\telse:\n",
    "\t\t    return \"O primeiro numero não é > que o segundo\"\n",
    "\t\t\n",
    "\n",
    "num1 = 10\n",
    "num2 = 9\n",
    "result = verifica_numeros(num1,num2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vendas = [[120, 90, 140], [80, 110, 90], [130, 100, 140]]\n",
    "\n",
    "categorias = {0: 'Eletrônicos', 1: 'Vestuário', 2: 'Brinquedos'}\n",
    "\n",
    "for i, dia in enumerate(vendas):\n",
    "\n",
    "    for j, categoria in enumerate(dia):\n",
    "\n",
    "        if categoria > 100:\n",
    "\n",
    "            print(f\"Dia {i+1}, Categoria {categorias[j]}: {categoria}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagens = [\"Olá\", \"Novidades\", \"\", \"Promoção\"]\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < len(mensagens):\n",
    "\n",
    "    if not mensagens[i]:\n",
    "\n",
    "        break\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def gerar_anagramas_validos(palavra,lista_palavras_validas):\n",
    "\tanagramas = set(itertools.permutations(palavra))\n",
    "\treturn filter(lambda : x in lista_palavras_validas, map [''.join, anagramas])\n",
    "\n",
    "print (gerar_anagramas_validos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def gerar_anagramas_validos(palavra,lista_palavras_validas):\n",
    "\tanagramas = set(itertools,permutations(palavra))\n",
    "\treturn filter(lambia x: x in lista_palavras_validas, map(''.join, anagramas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes para limites de saldo e transações\n",
    "SALDO_ALTO_RISCO = 1000\n",
    "SALDO_MODERADO_RISCO = 5000\n",
    "TRANSACOES_SUSPEITAS_ALTO_RISCO = 2\n",
    "\n",
    "def classificar_risco_saldo(saldo):\n",
    "    \"\"\"Classifica o risco com base no saldo da conta.\"\"\"\n",
    "    if saldo < SALDO_ALTO_RISCO:\n",
    "        return \"Alto\"\n",
    "    elif saldo <= SALDO_MODERADO_RISCO:\n",
    "        return \"Moderado\"\n",
    "    else:\n",
    "        return \"Baixo\"\n",
    "\n",
    "def classificar_risco_transacoes(transacoes_suspeitas):\n",
    "    \"\"\"Classifica o risco com base no número de transações suspeitas.\"\"\"\n",
    "    if transacoes_suspeitas > TRANSACOES_SUSPEITAS_ALTO_RISCO:\n",
    "        return \"Alto\"\n",
    "    elif transacoes_suspeitas >= 1:\n",
    "        return \"Moderado\"\n",
    "    else:\n",
    "        return \"Baixo\"\n",
    "\n",
    "def ajustar_risco_por_tempo(risco, tempo_conta):\n",
    "    \"\"\"Ajusta o nível de risco com base no tempo de abertura da conta.\"\"\"\n",
    "    if tempo_conta < 1:\n",
    "        return \"Alto\" if risco != \"Alto\" else risco\n",
    "    elif tempo_conta > 5:\n",
    "        return \"Baixo\" if risco == \"Moderado\" else risco\n",
    "    else:\n",
    "        return risco\n",
    "\n",
    "def classificar_risco(saldo, transacoes_suspeitas, tempo_conta):\n",
    "    risco_saldo = classificar_risco_saldo(saldo)\n",
    "    risco_transacoes = classificar_risco_transacoes(transacoes_suspeitas)\n",
    "\n",
    "    # Correção: Utilizar um dicionário para mapear os níveis de risco para um valor que possa ser comparado\n",
    "    ordem_risco = {\"Baixo\": 0, \"Moderado\": 1, \"Alto\": 2}\n",
    "    risco_final = \"Alto\" if risco_saldo == \"Alto\" or risco_transacoes == \"Alto\" else max(risco_saldo, risco_transacoes, key=ordem_risco.get)\n",
    "\n",
    "    risco_ajustado = ajustar_risco_por_tempo(risco_final, tempo_conta)\n",
    "\n",
    "    return risco_ajustado\n",
    "\n",
    "# Dados da conta\n",
    "saldo = 1500\n",
    "transacoes_suspeitas = 1\n",
    "tempo_conta = 3  # em anos\n",
    "\n",
    "# Classificação de risco\n",
    "risco_conta = classificar_risco(saldo, transacoes_suspeitas, tempo_conta)\n",
    "print(f\"Classificação de risco da conta: {risco_conta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import random\n",
    "\n",
    "class BatalhaNaval:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Batalha Naval\")\n",
    "\n",
    "        self.tamanho_tabuleiro = 5\n",
    "        self.navios = 3\n",
    "        self.tabuleiro = [['O' for _ in range(self.tamanho_tabuleiro)] for _ in range(self.tamanho_tabuleiro)]\n",
    "        self.colocar_navios()\n",
    "\n",
    "        self.botao_tabuleiro = [[None for _ in range(self.tamanho_tabuleiro)] for _ in range(self.tamanho_tabuleiro)]\n",
    "        self.criar_interface()\n",
    "\n",
    "    def colocar_navios(self):\n",
    "        count = 0\n",
    "        while count < self.navios:\n",
    "            x, y = random.randint(0, self.tamanho_tabuleiro-1), random.randint(0, self.tamanho_tabuleiro-1)\n",
    "            if self.tabuleiro[x][y] == 'O':\n",
    "                self.tabuleiro[x][y] = 'N'\n",
    "                count += 1\n",
    "\n",
    "    def criar_interface(self):\n",
    "        for i in range(self.tamanho_tabuleiro):\n",
    "            for j in range(self.tamanho_tabuleiro):\n",
    "                self.botao_tabuleiro[i][j] = tk.Button(self.root, text=' ', width=6, height=3,\n",
    "                                                       command=lambda x=i, y=j: self.atirar(x, y))\n",
    "                self.botao_tabuleiro[i][j].grid(row=i, column=j)\n",
    "\n",
    "    def atirar(self, x, y):\n",
    "        if self.tabuleiro[x][y] == 'N':\n",
    "            self.botao_tabuleiro[x][y].config(text='X', bg='red')\n",
    "            self.tabuleiro[x][y] = 'X'\n",
    "        else:\n",
    "            self.botao_tabuleiro[x][y].config(text='-', bg='blue')\n",
    "            self.tabuleiro[x][y] = '-'\n",
    "        self.botao_tabuleiro[x][y].config(state='disabled')\n",
    "        self.verificar_vitoria()\n",
    "\n",
    "    def verificar_vitoria(self):\n",
    "        for linha in self.tabuleiro:\n",
    "            if 'N' in linha:\n",
    "                return\n",
    "        tk.messagebox.showinfo(\"Batalha Naval\", \"Você venceu!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = BatalhaNaval(root)\n",
    "    root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remover duplicatas\n",
    "file_path = \"D:\\Dados\\Fintech\\FinTech.xlsx\"\n",
    "transactions_df = pd.read_excel(file_path, sheet_name='Transações')\n",
    "transactions_df = transactions_df.drop_duplicates()\n",
    "\n",
    "# 2. Tratar valores ausentes (preenchendo com valores padrão ou removendo)\n",
    "transactions_df = transactions_df.fillna({\n",
    "    'Descrição': 'Desconhecido',\n",
    "    'Valor': 0,\n",
    "    'Categoria': 'Desconhecido',\n",
    "    'Conta': 'Desconhecido',\n",
    "    'Categoria Master': 'Desconhecido'\n",
    "})\n",
    "\n",
    "# 3. Padronizar formatação de datas e valores\n",
    "transactions_df['Data Ocorrência'] = pd.to_datetime(transactions_df['Data Ocorrência'])\n",
    "transactions_df['Valor'] = transactions_df['Valor'].astype(float)\n",
    "\n",
    "# 4. Remover espaços em branco desnecessários\n",
    "transactions_df['Descrição'] = transactions_df['Descrição'].str.strip()\n",
    "transactions_df['Categoria'] = transactions_df['Categoria'].str.strip()\n",
    "transactions_df['Conta'] = transactions_df['Conta'].str.strip()\n",
    "transactions_df['Categoria Master'] = transactions_df['Categoria Master'].str.strip()\n",
    "\n",
    "# Verificando o resultado da limpeza\n",
    "transactions_df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o arquivo Excel\n",
    "file_path = \"D:\\Dados\\Fintech\\FinTech.xlsx\"\n",
    "transactions_df = pd.read_excel(file_path, sheet_name='Transações')\n",
    "\n",
    "# 1. Remover duplicatas\n",
    "transactions_df = transactions_df.drop_duplicates()\n",
    "\n",
    "# 2. Tratar valores ausentes (preenchendo com valores padrão ou removendo)\n",
    "transactions_df = transactions_df.fillna({\n",
    "    'Descrição': 'Desconhecido',\n",
    "    'Valor': 0,\n",
    "    'Categoria': 'Desconhecido',\n",
    "    'Conta': 'Desconhecido',\n",
    "    'Categoria Master': 'Desconhecido'\n",
    "})\n",
    "\n",
    "# 3. Padronizar formatação de datas e valores\n",
    "transactions_df['Data Ocorrência'] = pd.to_datetime(transactions_df['Data Ocorrência'])\n",
    "transactions_df['Valor'] = transactions_df['Valor'].astype(float)\n",
    "\n",
    "# 4. Remover espaços em branco desnecessários\n",
    "transactions_df['Descrição'] = transactions_df['Descrição'].str.strip()\n",
    "transactions_df['Categoria'] = transactions_df['Categoria'].str.strip()\n",
    "transactions_df['Conta'] = transactions_df['Conta'].str.strip()\n",
    "transactions_df['Categoria Master'] = transactions_df['Categoria Master'].str.strip()\n",
    "\n",
    "# Exibir o resultado da limpeza\n",
    "transactions_df.head()\n",
    "\n",
    "# Resumo estatístico dos dados numéricos\n",
    "summary_statistics = transactions_df.describe()\n",
    "summary_statistics\n",
    "\n",
    "# Agrupar por 'Categoria' e calcular a soma dos 'Valores'\n",
    "grouped_by_category = transactions_df.groupby('Categoria')['Valor'].sum().reset_index()\n",
    "grouped_by_category\n",
    "\n",
    "\n",
    "# Adicionar uma coluna para o mês\n",
    "transactions_df['Mês'] = transactions_df['Data Ocorrência'].dt.to_period('M')\n",
    "\n",
    "# Criar uma tabela dinâmica\n",
    "pivot_table = transactions_df.pivot_table(\n",
    "    values='Valor', \n",
    "    index='Mês', \n",
    "    columns='Categoria', \n",
    "    aggfunc='sum', \n",
    "    fill_value=0\n",
    ")\n",
    "pivot_table\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o arquivo Excel\n",
    "file_path = \"D:\\Dados\\Fintech\\FinTech.xlsx\"\n",
    "transactions_df = pd.read_excel(file_path, sheet_name='Transações')\n",
    "\n",
    "# Resumo estatístico dos dados numéricos\n",
    "summary_statistics = transactions_df.describe()\n",
    "print(summary_statistics)\n",
    "\n",
    "\n",
    "# Agrupar por 'Categoria' e calcular a soma dos 'Valores'\n",
    "grouped_by_category = transactions_df.groupby('Categoria')['Valor'].sum().reset_index()\n",
    "print(grouped_by_category)\n",
    "\n",
    "\n",
    "# Adicionar uma coluna para o mês\n",
    "transactions_df['Mês'] = transactions_df['Data Ocorrência'].dt.to_period('M')\n",
    "\n",
    "# Criar uma tabela dinâmica com a soma dos valores por categoria e mês\n",
    "pivot_table = transactions_df.pivot_table(\n",
    "    values='Valor', \n",
    "    index='Mês', \n",
    "    columns='Categoria', \n",
    "    aggfunc='sum', \n",
    "    fill_value=0\n",
    ")\n",
    "print(pivot_table)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
