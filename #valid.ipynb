{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Rastreamento de objetos unicos \n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Carregar o vídeo\n",
    "video_path = 'D:/Dados/Material_complementar_rastreamento_objetos/videos/race.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Inicializar o rastreador\n",
    "tracker = cv2.TrackerCSRT_create()\n",
    "\n",
    "# Ler o primeiro frame do vídeo\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Erro ao ler o vídeo\")\n",
    "    exit()\n",
    "\n",
    "# Selecionar a região de interesse (ROI) para rastrear\n",
    "bbox = cv2.selectROI(\"Selecione o objeto a ser rastreado\", frame, False)\n",
    "tracker.init(frame, bbox)\n",
    "\n",
    "while True:\n",
    "    # Ler o próximo frame do vídeo\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Atualizar o rastreador com o novo frame\n",
    "    success, bbox = tracker.update(frame)\n",
    "    \n",
    "    # Desenhar a região rastreada no frame\n",
    "    if success:\n",
    "        x, y, w, h = [int(v) for v in bbox]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    else:\n",
    "        cv2.putText(frame, \"Perda de rastreamento\", (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "    \n",
    "    # Exibir o frame com a região rastreada\n",
    "    cv2.imshow(\"Rastreamento de objeto\", frame)\n",
    "    \n",
    "    # Verificar se o usuário pressionou a tecla 'q' para sair do loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar o objeto de captura e fechar todas as janelas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test\n",
    "\n",
    "#Rastreamento de objetos unicos \n",
    "\n",
    "# Importando bibliotecas\n",
    "import cv2\n",
    "import sys\n",
    "from random import randint\n",
    "\n",
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "# Declarando os tipos de algoritmos de rastreamento\n",
    "tracker_types = ['BOOSTING', 'MIL', 'KCF', 'TLD', 'MEDIANFLOW', 'MOSSE', 'CSRT']\n",
    "# Escolhendo o algoritmo 0: BOOSTING, 1: MIL, 2: KCF, 3: TLD, 4: MEDIANFLOW, 5: MOSSE, 6: CSRT\n",
    "tracker_type = tracker_types[2] # Indique o classificador\n",
    "print(tracker_type)\n",
    "\n",
    "if int(minor_ver) < 3:\n",
    "    tracker = tracker_type\n",
    "else:\n",
    "# Verificando qual o algoritmo escolhido\n",
    "   if tracker_type == 'BOOSTING':\n",
    "       tracker = cv2.legacy.TrackerBoosting_create()\n",
    "   if tracker_type == 'MIL':\n",
    "       tracker = cv2.legacy.TrackerMIL_create()\n",
    "   if tracker_type == 'KCF':\n",
    "       tracker = cv2.legacy.TrackerKCF_create()\n",
    "   if tracker_type == 'TLD':\n",
    "       tracker = cv2.legacy.TrackerTLD_create()\n",
    "   if tracker_type == 'MEDIANFLOW':\n",
    "       tracker = cv2.legacy.TrackerMedianFlow_create()\n",
    "   if tracker_type == 'MOSSE':\n",
    "       tracker = cv2.legacy.TrackerMOSSE_create()\n",
    "   if tracker_type == 'CSRT':\n",
    "       tracker = cv2.legacy.TrackerCSRT_create()\n",
    "\n",
    "video_path = 'D:/Dados/Material_complementar_rastreamento_objetos/videos/race.mp4'\n",
    "\n",
    "video = cv2.VideoCapture(video_path) # Localize o caminho do vídeo para análise, na pasta videos.\n",
    "if not video.isOpened():\n",
    "    print('Não foi possível carregar o vídeo')\n",
    "    sys.exit()\n",
    "\n",
    "ok, frame = video.read() # Habilita a leitura do vídeo\n",
    "if not ok:\n",
    "    print('Não foi possível ler o arquivo de vídeo')\n",
    "    sys.exit()\n",
    "\n",
    "bbox = cv2.selectROI(frame, False) # Cria o retângulo no objeto de interesse.\n",
    "\n",
    "ok = tracker.init(frame, bbox) # Habilita o rastreamento do objeto.\n",
    "\n",
    "colors = (randint(0, 255), randint(0, 255), randint(0, 255)) # Seleciona uma cor aleatória para o retângulo.\n",
    "\n",
    "# Comandos para rastrear o objeto enquando vídeo estiver ativo.\n",
    "while True:\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    timer = cv2.getTickCount()\n",
    "    ok, bbox = tracker.update(frame)\n",
    "\n",
    "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
    "\n",
    "    if ok:\n",
    "        (x, y, w, h) = [int(v) for v in bbox]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), colors, 2, 1)\n",
    "    else:\n",
    "        cv2.putText(frame, 'Falha no rastreamento', (100, 80),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.putText(frame, tracker_type + ' Tracker', (100, 20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.putText(frame, 'FPS: ' + str(int(fps)), (100, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('Tracking', frame)\n",
    "    if cv2.waitKey(1) & 0XFF == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercicio  70\n",
    "#Implemente um algoritmo, em Python, de Aprendizado de Máquina para\n",
    "#construir um algoritmo de rastreamento de objetos pela webcam.\n",
    "\n",
    "\n",
    "\n",
    "# Importando bibliotecas\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Inicializa a captura pela webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Leitura do primeiro frame e transformação em esacala de cinza.\n",
    "ret, frame = cap.read()\n",
    "frame_gray_init = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Utilização do método de estimativa de fluxo óptico\n",
    "parameters_lucas_kanade = dict(winSize=(15, 15),\n",
    "                               maxLevel=4,\n",
    "                               criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Define uma função para selecionar um ponto de interesse no frame com um clique do mouse\n",
    "def select_point(event, x, y, flags, params):\n",
    "    global point, selected_point, old_points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        point = (x, y)\n",
    "        selected_point = True # Indica que um ponto foi selecionado\n",
    "        old_points = np.array([[x, y]], dtype=np.float32) # Armazena o ponto como array NumPy\n",
    "# Cria uma janela chamada 'Frame' e define a função 'select_point' como callback para eventos do mouse\n",
    "cv2.namedWindow('Frame')\n",
    "cv2.namedWindow('Frame')\n",
    "cv2.setMouseCallback('Frame', select_point)\n",
    "\n",
    "# Inicializa variáveis para controle do ponto selecionado\n",
    "selected_point = False\n",
    "point = ()\n",
    "old_points = np.array([[]])\n",
    "\n",
    "# Cria uma máscara com as mesmas dimensões e tipo do frame para desenhar o rastreamento\n",
    "mask = np.zeros_like(frame)\n",
    "\n",
    "# Loop principal para processamento de cada frame capturado pela webcam\n",
    "while True:\n",
    "    ret, frame = cap.read() # Lê o próximo frame\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Converte o frame atual para escala de cinza\n",
    "    # Se um ponto foi selecionado\n",
    "    if selected_point is True:\n",
    "        cv2.circle(frame, point, 5, (0, 0, 255), 2) # Desenha um círculo no frame no ponto selecionado\n",
    "        # Calcula o fluxo óptico de Lucas-Kanade para o frame atual\n",
    "        new_points, status, errors = cv2.calcOpticalFlowPyrLK(frame_gray_init,\n",
    "                                                              frame_gray,\n",
    "                                                              old_points,\n",
    "                                                              None,\n",
    "                                                              **parameters_lucas_kanade)\n",
    "        # Atualiza o frame inicial para o frame atual\n",
    "        frame_gray_init = frame_gray.copy()\n",
    "        old_points = new_points # Atualiza os pontos antigos para os novos pontos calculados\n",
    "        # Extrai as coordenadas dos pontos\n",
    "        x, y = new_points.ravel().astype(int)\n",
    "        j, k = old_points.ravel().astype(int)\n",
    "\n",
    "        mask = cv2.line(mask, (x, y), (j, k), (0, 255, 255), 2) # Desenho de uma linha indicando o rastreamento;\n",
    "        frame = cv2.circle(frame, (x, y), 5, (0, 255, 0), -1) # Demarcação de um ponto do objeto de rastreamento;\n",
    "    # Combina o frame e a máscara\n",
    "    img = cv2.add(frame, mask)\n",
    "    # Exibe o frame e a máscara em janelas separadas\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Frame 2\", mask)\n",
    "    # Aguarda por uma tecla ser pressionada; se a tecla ESC for pressionada, interrompe o loop\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "# Libera a captura de vídeo e fecha todas as janelas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implemente um algoritmo, em Python, de Aprendizado de Máquina para\n",
    "#construir um algoritmo de rastreamento de objetos pela webcam.\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Função para selecionar o objeto a ser rastreado\n",
    "def selecionar_objeto(frame):\n",
    "    bbox = cv2.selectROI(\"Selecione o objeto\", frame, False)\n",
    "    return bbox\n",
    "\n",
    "# Captura de vídeo da webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Verifica se a webcam está funcionando corretamente\n",
    "if not cap.isOpened():\n",
    "    print(\"Erro ao abrir a webcam\")\n",
    "    exit()\n",
    "\n",
    "# Leitura do primeiro frame\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Seleciona o objeto a ser rastreado\n",
    "bbox = selecionar_objeto(frame)\n",
    "\n",
    "# Inicializa o rastreador KCF\n",
    "tracker = cv2.TrackerKCF_create()\n",
    "\n",
    "# Inicializa o rastreamento\n",
    "ok = tracker.init(frame, bbox)\n",
    "\n",
    "while True:\n",
    "    # Captura um novo frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Atualiza o rastreamento\n",
    "    ok, bbox = tracker.update(frame)\n",
    "\n",
    "    # Desenha a caixa delimitadora do objeto rastreado\n",
    "    if ok:\n",
    "        p1 = (int(bbox[0]), int(bbox[1]))\n",
    "        p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "        cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "    else:\n",
    "        cv2.putText(frame, \"Erro de rastreamento\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "    # Mostra o frame com a caixa delimitadora\n",
    "    cv2.imshow(\"Rastreamento de objetos\", frame)\n",
    "\n",
    "    # Sai do loop se a tecla 'q' for pressionada\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Libera os recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread() \u001b[38;5;66;03m# Lê o frame atual do vídeo\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     frame_gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Converte o frame atual para escala de cinza\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Calcula o fluxo óptico de Lucas-Kanade para os pontos de interesse detectados anteriormente\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     new_edges, status, errors \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalcOpticalFlowPyrLK(frame_gray_init,\n\u001b[0;32m     45\u001b[0m                                                          frame_gray,\n\u001b[0;32m     46\u001b[0m                                                          edges,\n\u001b[0;32m     47\u001b[0m                                                          \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m                                                          \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameters_lucas_kanade)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "#Exercicio  71 \n",
    "#Implemente um algoritmo, em Python, de Aprendizado de Máquina para\n",
    "#rastreamento de objeto, com análise do movimento em um vídeo, aplicando o\n",
    "#conceito de fluxo óptico esparso.\n",
    "\n",
    "\n",
    "\n",
    "# Importando bibliotecas\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Carrega um vídeo para análise do arquivo especificado\n",
    "video_path = \"D:/Dados/Material_complementar_rastreamento_objetos/videos/walking.avi\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Configura os parâmetros para o detector de cantos Shi-Tomasi\n",
    "parameters_shitomasi = dict(maxCorners=100,\n",
    "                            qualityLevel=0.3,\n",
    "                            minDistance=7)\n",
    "# Configura os parâmetros para o algoritmo de Lucas-Kanade para o fluxo óptico\n",
    "parameters_lucas_kanade = dict(winSize=(15, 15),\n",
    "                               maxLevel=2,\n",
    "                               criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "# Gera cores aleatórias para representar os pontos de interesse\n",
    "colors = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "# Lê o primeiro frame do vídeo\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Converte o primeiro frame para escala de cinza\n",
    "frame_gray_init = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detecta os pontos de interesse no primeiro frame usando o detector de cantos Shi-Tomasi\n",
    "edges = cv2.goodFeaturesToTrack(frame_gray_init, mask=None, **parameters_shitomasi)\n",
    "\n",
    "# Cria uma máscara com as mesmas dimensões e tipo do frame para desenhar o trajeto dos pontos\n",
    "mask = np.zeros_like(frame)\n",
    "\n",
    "# Loop para processar cada frame do vídeo\n",
    "while True:\n",
    "    ret, frame = cap.read() # Lê o frame atual do vídeo\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Converte o frame atual para escala de cinza\n",
    "    # Calcula o fluxo óptico de Lucas-Kanade para os pontos de interesse detectados anteriormente\n",
    "    new_edges, status, errors = cv2.calcOpticalFlowPyrLK(frame_gray_init,\n",
    "                                                         frame_gray,\n",
    "                                                         edges,\n",
    "                                                         None,\n",
    "                                                         **parameters_lucas_kanade)\n",
    "    # Filtra os novos pontos de interesse com base no status\n",
    "    news = new_edges[status == 1]\n",
    "    olds = edges[status == 1]\n",
    "\n",
    "    # Itera sobre os pontos antigos e novos para atualizar o trajeto\n",
    "    for i, (new, old) in enumerate(zip(news, olds)):\n",
    "        a, b = new.ravel().astype(int)\n",
    "        c, d = old.ravel().astype(int)\n",
    "\n",
    "        # Desenha uma linha na máscara para indicar o trajeto do ponto\n",
    "        mask = cv2.line(mask, (a, b), (c, d), colors[i].tolist(), 2)\n",
    "        # Desenha um círculo no frame para marcar o ponto de interesse\n",
    "        frame = cv2.circle(frame, (a, b), 5, colors[i].tolist(), -1)\n",
    "\n",
    "    img = cv2.add(frame, mask) # Combina o frame e a máscara\n",
    "\n",
    "    # Exibe o resultado do fluxo óptico esparsa em uma janela\n",
    "    cv2.imshow('Sparce Optical flow', img)\n",
    "    if cv2.waitKey(1) == 13:     # Aguarda por uma tecla ser pressionada; se a tecla 'Enter' for pressionada, interrompe o loop\n",
    "        break\n",
    "\n",
    "    # Atualiza o frame inicial para o frame atual para a próxima iteração\n",
    "    frame_gray_init = frame_gray.copy()\n",
    "    # Atualiza os pontos de interesse para os novos pontos\n",
    "    edges = news.reshape(-1, 1, 2)\n",
    "\n",
    "# Fecha todas as janelas abertas e libera a captura de vídeo\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
